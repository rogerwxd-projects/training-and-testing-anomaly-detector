{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "952482e1-9a78-4a2e-a5e6-ae6a0a1b49a7",
   "metadata": {},
   "source": [
    "## 01 - Network Attack Detection with Machine Learning (Brute Force)\n",
    "\n",
    "A **Network Intrusion Detection System (NIDS)** is a security technology designed to detect malicious or suspicious activities on a network. NIDS monitors network traffic in real-time, analyzing data packets and looking for patterns that may indicate an attack or anomalous behavior. For this experiment, the constructed NIDS has four stages:\n",
    "\n",
    "1. **Data Acquisition**: Collecting data from a network environment.\n",
    "2. **Feature Extraction**: Extracting features from network events.\n",
    "3. **Classification**: Classifying using a Machine Learning algorithm.\n",
    "4. **Alert**: Generating an alert for the operator on network events classified as attacks by the algorithm.\n",
    "\n",
    "The purpose of the experiment is to identify brute force attacks in a corporate network environment, where a web system is attacked, and the algorithm can accurately identify the attacker.\n",
    "\n",
    "In the first stage, Data Acquisition, the experiment was conducted using an environment with 10 virtual machines with a web system receiving legitimate network operations from both internal and external sources. To represent a corporate environment, about 100 bots were used to perform legitimate actions on the web system randomly within short periods. These actions were monitored and collected, generating a PCAP file with about 5 million network events over 72 hours. A PCAP file containing about 1 million attack events was also generated to validate whether the algorithm could learn and identify the behavior of a brute force attack. A second PCAP file was created by performing various attacks in the environment alongside the legitimate actions of the bots, aiming for the machine learning algorithm to identify the attacks within the common network traffic.\n",
    "\n",
    "In the second stage, a feature extraction algorithm was created, available at the URL: [PacketTraitAnalyzer](https://github.com/rogerwxd-projects/PacketTraitAnalyzer), capable of extracting various features that represent network behavior for subsequent application of machine learning algorithms.\n",
    "\n",
    "In the third stage, several machine learning algorithms were used to create a model that captures the knowledge of the legitimate environment and classifies divergent behaviors as anomalies. In this scenario, four anomaly detection algorithms were used: Isolation Forest, LOF (Local Outlier Factor), One-Class SVM, and Autoencoder. During training, each algorithm achieved about 88% to 95% accuracy in the legitimate environment, with a few randomly created attacks by the bots to force the identification of some abnormal behaviors even during learning.\n",
    "\n",
    "Below is the execution of training and validation, followed by the test to validate if the algorithm can identify network attacks as anomalies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ae821b-974b-4df1-a13e-59ba7d4646c2",
   "metadata": {},
   "source": [
    "# Training the algorithms\n",
    "\n",
    "During the training, some features that did not make sense for the algorithm's learning were removed, except in cases where correct identification of the attacker is necessary. These features are: StartTime, EndTime, SourceIP, DestinationIP, SourcePort, DestinationPort, Protocol, Flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b931645a-f8ed-4e4f-a1f8-24a29577dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Dataset ##\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv('dataset/dataset-full.csv')\n",
    "columns_to_remove = ['StartTime','EndTime','SourceIP','DestinationIP','SourcePort','DestinationPort','Protocol','Flags']\n",
    "df = df.drop(columns=columns_to_remove)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "train_df, test_df = train_test_split(df_scaled, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "235ab5d3-d627-4535-90d2-1691f44df9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation Forest:\n",
      "Accuracy: 89.92%\n"
     ]
    }
   ],
   "source": [
    "## Training Isolation Forest ##\n",
    "isolation_forest = IsolationForest(n_estimators=100, contamination=0.1, random_state=42)\n",
    "isolation_forest.fit(train_df)\n",
    "joblib.dump(isolation_forest, 'model/isolation_forest_model.joblib')\n",
    "\n",
    "test_predictions = isolation_forest.predict(test_df)\n",
    "correct_predictions = np.sum(test_predictions == 1)  # Conta o número de previsões corretas (pontos normais)\n",
    "total_samples = len(test_df)\n",
    "accuracy = correct_predictions / total_samples * 100\n",
    "\n",
    "print(\"Isolation Forest:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a0a733-5e99-40fb-a197-246078df9996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Local Outlier Factor (LOF):\n",
      "Accuracy: 88.53%\n"
     ]
    }
   ],
   "source": [
    "## Training Local Outlier Factor (LOF) ##\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1, novelty=True)\n",
    "lof.fit(train_df)\n",
    "joblib.dump(lof, 'model/lof_model.joblib')\n",
    "\n",
    "test_predictions = lof.predict(test_df)\n",
    "correct_predictions = np.sum(test_predictions == 1)  # Conta o número de previsões corretas (pontos normais)\n",
    "accuracy = correct_predictions / total_samples * 100\n",
    "\n",
    "print(\"\\nLocal Outlier Factor (LOF):\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f3ccae-0b54-43ec-9e44-c52778c67e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-Class SVM:\n",
      "Accuracy: 89.85%\n"
     ]
    }
   ],
   "source": [
    "## One-Class SVM ##\n",
    "one_class_svm = OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n",
    "one_class_svm.fit(train_df)\n",
    "joblib.dump(one_class_svm, 'model/one_class_svm_model.joblib')\n",
    "\n",
    "test_predictions = one_class_svm.predict(test_df)\n",
    "correct_predictions = np.sum(test_predictions == 1)\n",
    "accuracy = correct_predictions / total_samples * 100\n",
    "\n",
    "print(\"\\nOne-Class SVM:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d036cd5-f215-41a1-884e-c84b2195a022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.7680 - val_loss: 0.6368\n",
      "Epoch 2/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 989us/step - loss: 0.6589 - val_loss: 0.6337\n",
      "Epoch 3/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 0.5950 - val_loss: 0.6302\n",
      "Epoch 4/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 987us/step - loss: 0.6799 - val_loss: 0.6276\n",
      "Epoch 5/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 986us/step - loss: 0.6966 - val_loss: 0.6273\n",
      "Epoch 6/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 989us/step - loss: 0.6093 - val_loss: 0.6136\n",
      "Epoch 7/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 994us/step - loss: 0.5994 - val_loss: 0.6133\n",
      "Epoch 8/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 982us/step - loss: 0.6462 - val_loss: 0.6131\n",
      "Epoch 9/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 987us/step - loss: 0.6317 - val_loss: 0.6131\n",
      "Epoch 10/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 0.6680 - val_loss: 0.6131\n",
      "Epoch 11/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 0.6251 - val_loss: 0.6130\n",
      "Epoch 12/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 983us/step - loss: 0.5302 - val_loss: 0.6130\n",
      "Epoch 13/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 992us/step - loss: 0.6064 - val_loss: 0.6130\n",
      "Epoch 14/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 983us/step - loss: 0.6311 - val_loss: 0.6129\n",
      "Epoch 15/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 974us/step - loss: 0.6109 - val_loss: 0.6129\n",
      "Epoch 16/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 976us/step - loss: 0.6866 - val_loss: 0.6129\n",
      "Epoch 17/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 977us/step - loss: 0.6307 - val_loss: 0.6129\n",
      "Epoch 18/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 975us/step - loss: 0.5992 - val_loss: 0.6129\n",
      "Epoch 19/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 979us/step - loss: 0.6130 - val_loss: 0.6128\n",
      "Epoch 20/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 974us/step - loss: 0.5870 - val_loss: 0.6132\n",
      "Epoch 21/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 967us/step - loss: 0.6782 - val_loss: 0.6129\n",
      "Epoch 22/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 957us/step - loss: 0.6295 - val_loss: 0.6129\n",
      "Epoch 23/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 981us/step - loss: 0.5893 - val_loss: 0.6134\n",
      "Epoch 24/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 977us/step - loss: 0.6282 - val_loss: 0.6094\n",
      "Epoch 25/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 973us/step - loss: 0.6271 - val_loss: 0.6088\n",
      "Epoch 26/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 982us/step - loss: 0.5872 - val_loss: 0.6084\n",
      "Epoch 27/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 981us/step - loss: 0.6342 - val_loss: 0.6083\n",
      "Epoch 28/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 981us/step - loss: 0.6316 - val_loss: 0.6083\n",
      "Epoch 29/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 959us/step - loss: 0.6077 - val_loss: 0.6083\n",
      "Epoch 30/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 976us/step - loss: 0.6569 - val_loss: 0.6083\n",
      "Epoch 31/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 960us/step - loss: 0.6690 - val_loss: 0.6088\n",
      "Epoch 32/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 970us/step - loss: 0.6757 - val_loss: 0.6083\n",
      "Epoch 33/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 977us/step - loss: 0.5977 - val_loss: 0.6085\n",
      "Epoch 34/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 968us/step - loss: 0.5788 - val_loss: 0.6083\n",
      "Epoch 35/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 977us/step - loss: 0.6695 - val_loss: 0.6080\n",
      "Epoch 36/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 984us/step - loss: 0.5669 - val_loss: 0.6063\n",
      "Epoch 37/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 967us/step - loss: 0.6157 - val_loss: 0.6062\n",
      "Epoch 38/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 972us/step - loss: 0.6705 - val_loss: 0.5966\n",
      "Epoch 39/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 968us/step - loss: 0.6329 - val_loss: 0.5978\n",
      "Epoch 40/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 980us/step - loss: 0.7194 - val_loss: 0.5964\n",
      "Epoch 41/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 973us/step - loss: 0.5656 - val_loss: 0.5954\n",
      "Epoch 42/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 978us/step - loss: 0.5830 - val_loss: 0.5952\n",
      "Epoch 43/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 988us/step - loss: 0.5680 - val_loss: 0.5952\n",
      "Epoch 44/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 982us/step - loss: 0.6957 - val_loss: 0.5953\n",
      "Epoch 45/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 982us/step - loss: 0.5988 - val_loss: 0.5953\n",
      "Epoch 46/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 987us/step - loss: 0.6215 - val_loss: 0.5952\n",
      "Epoch 47/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 0.5789 - val_loss: 0.5952\n",
      "Epoch 48/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 962us/step - loss: 0.6510 - val_loss: 0.5951\n",
      "Epoch 49/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 938us/step - loss: 0.4759 - val_loss: 0.5953\n",
      "Epoch 50/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 950us/step - loss: 0.5433 - val_loss: 0.5952\n",
      "Epoch 51/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 941us/step - loss: 0.6063 - val_loss: 0.5952\n",
      "Epoch 52/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 940us/step - loss: 0.6585 - val_loss: 0.5951\n",
      "Epoch 53/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 953us/step - loss: 0.6232 - val_loss: 0.5951\n",
      "Epoch 54/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 944us/step - loss: 0.5618 - val_loss: 0.5949\n",
      "Epoch 55/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 953us/step - loss: 0.6353 - val_loss: 0.5948\n",
      "Epoch 56/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 946us/step - loss: 0.5953 - val_loss: 0.5948\n",
      "Epoch 57/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 954us/step - loss: 0.6466 - val_loss: 0.5949\n",
      "Epoch 58/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 950us/step - loss: 0.5243 - val_loss: 0.5947\n",
      "Epoch 59/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 940us/step - loss: 0.5991 - val_loss: 0.5949\n",
      "Epoch 60/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 952us/step - loss: 0.5976 - val_loss: 0.5948\n",
      "Epoch 61/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 948us/step - loss: 0.5876 - val_loss: 0.5948\n",
      "Epoch 62/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 937us/step - loss: 0.5850 - val_loss: 0.5947\n",
      "Epoch 63/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 951us/step - loss: 0.5758 - val_loss: 0.5952\n",
      "Epoch 64/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 949us/step - loss: 0.5607 - val_loss: 0.5949\n",
      "Epoch 65/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 952us/step - loss: 0.6157 - val_loss: 0.5946\n",
      "Epoch 66/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 949us/step - loss: 0.6438 - val_loss: 0.5950\n",
      "Epoch 67/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 950us/step - loss: 0.6255 - val_loss: 0.5947\n",
      "Epoch 68/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 947us/step - loss: 0.5386 - val_loss: 0.5946\n",
      "Epoch 69/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 958us/step - loss: 0.6719 - val_loss: 0.5947\n",
      "Epoch 70/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 950us/step - loss: 0.5977 - val_loss: 0.5947\n",
      "Epoch 71/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 950us/step - loss: 0.5693 - val_loss: 0.5946\n",
      "Epoch 72/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 951us/step - loss: 0.6218 - val_loss: 0.5946\n",
      "Epoch 73/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 959us/step - loss: 0.5970 - val_loss: 0.5946\n",
      "Epoch 74/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 955us/step - loss: 0.6223 - val_loss: 0.5946\n",
      "Epoch 75/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 958us/step - loss: 0.5518 - val_loss: 0.5945\n",
      "Epoch 76/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 940us/step - loss: 0.5720 - val_loss: 0.5946\n",
      "Epoch 77/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 952us/step - loss: 0.5878 - val_loss: 0.5945\n",
      "Epoch 78/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 952us/step - loss: 0.6873 - val_loss: 0.5945\n",
      "Epoch 79/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 953us/step - loss: 0.5484 - val_loss: 0.5947\n",
      "Epoch 80/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 953us/step - loss: 0.5531 - val_loss: 0.5946\n",
      "Epoch 81/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 949us/step - loss: 0.6700 - val_loss: 0.5945\n",
      "Epoch 82/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 946us/step - loss: 0.5655 - val_loss: 0.5945\n",
      "Epoch 83/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 950us/step - loss: 0.6474 - val_loss: 0.5946\n",
      "Epoch 84/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 951us/step - loss: 0.5864 - val_loss: 0.5945\n",
      "Epoch 85/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 943us/step - loss: 0.5906 - val_loss: 0.5944\n",
      "Epoch 86/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 948us/step - loss: 0.6046 - val_loss: 0.5950\n",
      "Epoch 87/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 973us/step - loss: 0.6614 - val_loss: 0.5945\n",
      "Epoch 88/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 958us/step - loss: 0.5688 - val_loss: 0.5945\n",
      "Epoch 89/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 952us/step - loss: 0.5391 - val_loss: 0.5945\n",
      "Epoch 90/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 961us/step - loss: 0.6260 - val_loss: 0.5946\n",
      "Epoch 91/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 950us/step - loss: 0.5539 - val_loss: 0.5945\n",
      "Epoch 92/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 960us/step - loss: 0.6376 - val_loss: 0.5944\n",
      "Epoch 93/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 953us/step - loss: 0.6978 - val_loss: 0.5946\n",
      "Epoch 94/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 953us/step - loss: 0.6276 - val_loss: 0.5944\n",
      "Epoch 95/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 959us/step - loss: 0.6451 - val_loss: 0.5945\n",
      "Epoch 96/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 958us/step - loss: 0.7060 - val_loss: 0.5944\n",
      "Epoch 97/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 956us/step - loss: 0.5778 - val_loss: 0.5944\n",
      "Epoch 98/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 962us/step - loss: 0.5741 - val_loss: 0.5944\n",
      "Epoch 99/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 961us/step - loss: 0.5442 - val_loss: 0.5943\n",
      "Epoch 100/100\n",
      "\u001b[1m6655/6655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 954us/step - loss: 0.5759 - val_loss: 0.5944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3169/3169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 688us/step\n",
      "\n",
      "Autoencoder:\n",
      "Accuracy: 95.00%\n"
     ]
    }
   ],
   "source": [
    "## Training Autoencoder ##\n",
    "input_dim = train_df.shape[1]\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(14, activation=\"relu\")(input_layer)\n",
    "encoder = Dense(7, activation=\"relu\")(encoder)\n",
    "encoder = Dense(3, activation=\"relu\")(encoder)\n",
    "decoder = Dense(7, activation=\"relu\")(encoder)\n",
    "decoder = Dense(14, activation=\"relu\")(decoder)\n",
    "decoder = Dense(input_dim, activation=\"sigmoid\")(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "autoencoder.fit(train_df, train_df, epochs=100, batch_size=32, shuffle=True, validation_split=0.1)\n",
    "autoencoder.save('model/autoencoder_model.h5')\n",
    "joblib.dump(scaler, 'model/autoencoder_scaler.joblib')\n",
    "\n",
    "reconstructions = autoencoder.predict(test_df)\n",
    "mse = np.mean(np.power(test_df - reconstructions, 2), axis=1)\n",
    "threshold = np.percentile(mse, 95)\n",
    "anomalies = (mse > threshold).astype(int)\n",
    "correct_predictions = np.sum(anomalies == 0)\n",
    "accuracy = correct_predictions / total_samples * 100\n",
    "\n",
    "print(\"\\nAutoencoder:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996b6110-2e5c-4982-9129-c57f51a2f7a3",
   "metadata": {},
   "source": [
    "# Testing the algorithms to validate if network attacks were identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d439f223-1615-4022-91d0-4d1daeabae95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Isolation Forest\n",
      "Accuracy: 100.00%\n",
      "\n",
      "Test Local Outlier Factor (LOF)\n",
      "Accuracy: 99.63%\n",
      "\n",
      "Test One-class SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.88%\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "Teste - Autoencoder:\n",
      "Accuracy: 94.91%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "dataset = 'dataset/attack.csv'\n",
    "\n",
    "def load_and_scale_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    columns_to_remove = ['StartTime', 'EndTime', 'SourceIP', 'DestinationIP', 'SourcePort', 'DestinationPort', 'Protocol', 'Flags']\n",
    "    df = df.drop(columns=columns_to_remove)\n",
    "    scaler = joblib.load('model/autoencoder_scaler.joblib')\n",
    "    df_scaled = scaler.transform(df)\n",
    "    return df, df_scaled\n",
    "\n",
    "new_df, new_df_scaled = load_and_scale_data(dataset)\n",
    "\n",
    "def predict_anomalies(model, df, df_scaled, model_name):\n",
    "    predictions = model.predict(df_scaled)\n",
    "    df['anomaly'] = predictions\n",
    "    anomalies_indices = np.where(predictions == -1)[0]\n",
    "    anomalies_lines = anomalies_indices + 1\n",
    "    anomaly_counts = len(anomalies_indices)\n",
    "    normals_count = len(df) - anomaly_counts\n",
    "    accuracy = anomaly_counts / len(new_df_scaled) * 100\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nTest Isolation Forest\")\n",
    "isolation_forest = joblib.load('model/isolation_forest_model.joblib')\n",
    "predict_anomalies(isolation_forest, new_df.copy(), new_df_scaled, 'isolation_forest')\n",
    "\n",
    "print(\"\\nTest Local Outlier Factor (LOF)\")\n",
    "lof = joblib.load('model/lof_model.joblib')\n",
    "predict_anomalies(lof, new_df.copy(), new_df_scaled, 'lof')\n",
    "\n",
    "print(\"\\nTest One-class SVM\")\n",
    "one_class_svm = joblib.load('model/one_class_svm_model.joblib')\n",
    "predict_anomalies(one_class_svm, new_df.copy(), new_df_scaled, 'one_class_svm')\n",
    "\n",
    "autoencoder = load_model('model/autoencoder_model.h5')\n",
    "reconstructions = autoencoder.predict(new_df_scaled)\n",
    "mse = np.mean(np.power(new_df_scaled - reconstructions, 2), axis=1)\n",
    "threshold = np.percentile(mse, 95)\n",
    "anomalies = (mse > threshold).astype(int)\n",
    "correct_predictions = np.sum(anomalies == 0)\n",
    "accuracy = correct_predictions / len(new_df_scaled) * 100\n",
    "print(\"\\nTeste - Autoencoder:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e8f2b8-ff33-4ced-a1f9-d2278445ee58",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In conclusion, it was observed that the algorithms were able to identify network attack behavior with an accuracy of at least **94%**, demonstrating that it is possible to create a project for identifying various types of attacks. This is noteworthy considering that the algorithms were used with their default settings and other parameters were not tested or optimized."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
